{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c59b3-f177-4a10-8925-d931ce572eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipelineLegacy, DDIMScheduler, AutoencoderKL\n",
    "from PIL import Image\n",
    "from ip_adapter import IPAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6dc69c-192d-4d74-8b1e-f0d9ccfbdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"/home/humw/Pretrain/stable-diffusion-v1-5\"\n",
    "vae_model_path = \"/home/humw/Pretrain/sd-vae-ft-mse\"\n",
    "image_encoder_path = \"/home/humw/Pretrain/h94/IP-Adapter/models/image_encoder\"\n",
    "ip_ckpt = \"/home/humw/Pretrain/h94/IP-Adapter/models/ip-adapter_sd15.bin\"\n",
    "device = \"cuda:4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec542f-8474-4f38-9457-073425578073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "noise_scheduler = DDIMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_start=0.00085,\n",
    "    beta_end=0.012,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    "    clip_sample=False,\n",
    "    set_alpha_to_one=False,\n",
    "    steps_offset=1,\n",
    ")\n",
    "vae = AutoencoderKL.from_pretrained(vae_model_path).to(dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8081d92-8f42-4bcd-9f83-44aec3f549a9",
   "metadata": {},
   "source": [
    "## Image Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849f9d0-5f68-4a49-9190-69dd50720cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SD pipeline\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    scheduler=noise_scheduler,\n",
    "    vae=vae,\n",
    "    feature_extractor=None,\n",
    "    safety_checker=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09e937-3904-4d8e-a559-9066502ded36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image prompt\n",
    "image = Image.open(\"assets/images/woman.png\")\n",
    "image.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e84e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refiner\n",
    "# \"/home/humw/Codes/FaceOff/output/VGGFace2_photomaker_max_out-512_refiner-blur3-min75-inter40_loss-n-mse_alpha6_eps16_num200/n000050/0012_01.png\"\n",
    "img_path = '/home/humw/Codes/FaceOff/output/VGGFace2_photomaker_max_out-512_refiner-blur3-min75-inter40_loss-n-mse_alpha6_eps16_num200/n000057/0012_01.png'\n",
    "image = Image.open(img_path)\n",
    "image.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "img_path = '/home/humw/Datasets/VGGFace2/n000057/set_B/0012_01.png'\n",
    "image = Image.open(img_path)\n",
    "image.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af034fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no refiner\n",
    "img_path = '/home/humw/Codes/FaceOff/output/VGGFace2_photomaker_max_out-512_loss-n-mse_alpha6_eps16_num200/n000057/0012_01.png'\n",
    "image = Image.open(img_path)\n",
    "image.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1ab06-d3ed-4a7e-a356-9ddf1a2eecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ip-adapter\n",
    "ip_model = IPAdapter(pipe, image_encoder_path, ip_ckpt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f52de-a9e4-44e1-aeec-8165414f1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image variations\n",
    "images = ip_model.generate(pil_image=image, num_samples=4, num_inference_steps=50, seed=42)\n",
    "grid = image_grid(images, 1, 4)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b84bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image variations\n",
    "images = ip_model.generate(pil_image=image, num_samples=4, num_inference_steps=50, seed=42)\n",
    "save_prompt_dir = '/home/humw/Codes/FaceOff/target_model/IP-Adapter-main/output'\n",
    "import os\n",
    "save_path = os.path.join(save_prompt_dir, 'n000057_no_refiner')\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for idx, image in enumerate(images):\n",
    "    image.save(os.path.join(save_path, f\"ipadapter_{idx:02d}.png\"))\n",
    "grid = image_grid(images, 1, 4)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61536bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image variations\n",
    "images = ip_model.generate(pil_image=image, num_samples=4, num_inference_steps=50, seed=42)\n",
    "grid = image_grid(images, 1, 4)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image variations\n",
    "images = ip_model.generate(pil_image=image, num_samples=4, num_inference_steps=50, seed=42)\n",
    "grid = image_grid(images, 1, 4)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf199405-7cb5-4f78-9973-5fe51c632a41",
   "metadata": {},
   "source": [
    "## Image-to-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f089ad0-4683-46d7-ab58-9e5fe8f34c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SD Img2Img pipe\n",
    "del pipe, ip_model\n",
    "torch.cuda.empty_cache()\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    scheduler=noise_scheduler,\n",
    "    vae=vae,\n",
    "    feature_extractor=None,\n",
    "    safety_checker=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db2b55-2f56-4eef-b2ca-c5126b14feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image prompt\n",
    "image = Image.open(\"assets/images/river.png\")\n",
    "g_image = Image.open(\"assets/images/vermeer.jpg\")\n",
    "image_grid([image.resize((256, 256)), g_image.resize((256, 256))], 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501f284-f295-4673-96ab-e34378da62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ip-adapter\n",
    "ip_model = IPAdapter(pipe, image_encoder_path, ip_ckpt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fff74-9ff2-46e6-bc8a-2ad4ae1fbe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate\n",
    "images = ip_model.generate(pil_image=image, num_samples=4, num_inference_steps=50, seed=42, image=g_image, strength=0.6)\n",
    "grid = image_grid(images, 1, 4)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a7c45-8697-411f-8374-3c81d5d972e3",
   "metadata": {},
   "source": [
    "## Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385cb339-3326-4523-a7db-b09e62d39c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SD Inpainting pipe\n",
    "del pipe, ip_model\n",
    "torch.cuda.empty_cache()\n",
    "pipe = StableDiffusionInpaintPipelineLegacy.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    scheduler=noise_scheduler,\n",
    "    vae=vae,\n",
    "    feature_extractor=None,\n",
    "    safety_checker=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f8ce5-eed0-41ef-9dbb-2272ec4bc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image prompt\n",
    "image = Image.open(\"assets/images/girl.png\")\n",
    "image.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b77289-65f5-459b-ada5-5c7c265bb4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = Image.open(\"assets/inpainting/image.png\").resize((512, 768))\n",
    "mask = Image.open(\"assets/inpainting/mask.png\").resize((512, 768))\n",
    "image_grid([masked_image.resize((256, 384)), mask.resize((256, 384))], 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49dbdaa-58eb-4bcf-acab-fa5e08f96dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ip-adapter\n",
    "ip_model = IPAdapter(pipe, image_encoder_path, ip_ckpt, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f6800-18b8-4d95-9f5e-e7035166cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate\n",
    "images = ip_model.generate(pil_image=image, num_samples=4, num_inference_steps=50,\n",
    "                           seed=42, image=masked_image, mask_image=mask, strength=0.7, )\n",
    "grid = image_grid(images, 1, 4)\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
